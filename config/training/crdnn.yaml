# Crdnn yaml training Configs

task:
  type: &task_type "VAD"
  name: "crdnn-vad"
  export_path: "tasks/debug"

dataset:
  train_data: "sample_data/vad_train_data.json"
  eval_data: "sample_data/vad_eval_data.json"
  noise_data: "sample_data/noise_data.json"
  min_dur_filter: 1.5
  batch_size: 32
  num_workers: 4
  chunk_size: 150
  
  feat_type: "fbank"
  feat_config:
    num_mel_bins: &feat_dim 64
    frame_length: 25
    frame_shift: 10
    dither: 0.0
    samplerate: 16000

  add_noise_proportion: 0.6 # Control noisify augmention ratio
  add_noise_config:
    min_snr_db: 10
    max_snr_db: 50
    max_gain_db: 300.0
  
  volume_perturb_config: 
    min_gain: 0.1
    max_gain: 1.5

vad_model:
  model: "Crdnn" # Nano size, 16.9k params works fine.
  config:
    cnn_block_config:
      num_layers: 2
      conv_type: "conv2d"
      input_dim: *feat_dim # should be consist with feat_dim 
      in_channels_config: [1, 16]
      out_channels_config: [16, 16] 
      kernel_configs: [[3, 3], [3, 3]] 
      stride_configs: [2, 2]
      dilation_config: [[1, 1], [1, 1]]
    dnn_block_config:
      num_layers: 1
      hidden_dim: 32
    rnn_block_config:
      rnn_type: "gru" 
      hidden_size: 32
      num_layers: 1

loss:
  model: "CELoss" 
  config:
    dummy: -1

metric:
  config:
    task: *task_type 
    top_ks: null

optim_setup: 
  optimizer:
    type: "Adam" 
    config:
      lr: 0.001
  lr_scheduler:
    type: "Cosine_Annealing"
    config:
      T_max: 50000
    step_config: 
      interval: "step" # Default API of configure_optimizers
      frequency: 5  # Default API of configure_optimizers

# ----- "Warmup" ------
# lr_scheduler:
#   type: "Warmup" 
#   config:
#     warmup_steps: 20000 
#     step_config:
#       interval: "step"
#       frequency: 5

# ----- "ReduceLROnPlateau" -----
# lr_scheduler:
#   type: "ReduceLROnPlateau"
#   config:
#     mode: "min"
#     factor: 0.5
#   step_config: 
#     monitor: "val_loss" # Default API of configure_optimizers
#     frequency: 1  # Default API of configure_optimizers

trainer:
  accelerator: "gpu" 
  devices: 1 
  strategy: "ddp" 
  precision: "32-true"
  max_epochs: 2000
  val_check_interval: 1.0
  accumulate_grad_batches: 1

callbacks:
  model_chkpt_config:
    monitor: "acc"
    mode: "max"
    save_top_k: 10

finetune:
  base_model: null 
resume: null
